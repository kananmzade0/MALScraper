{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data and checking for anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json(\"../data/anime_full_details.json\")\n",
    "df2 = pd.read_json(\"../data/anime_list.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding ids to both dataframes for easier merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['id'] = df1['link'].apply(lambda x: x.split(\"/anime/\")[1].split(\"/\")[0] if isinstance(x, str) and \"/anime/\" in x else None)\n",
    "df2['id'] = df2['link'].apply(lambda x: x.split(\"/anime/\")[1].split(\"/\")[0] if isinstance(x, str) and \"/anime/\" in x else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the two dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full anime data (df1) has size of (28209, 24).\n",
      "Anime links data (df2) has size of (28210, 5).\n",
      "Merged table (df_merged) has a size of (28210, 25).\n"
     ]
    }
   ],
   "source": [
    "df_merged = pd.merge(left=df1, right=df2, how='right', on=['id'], suffixes=(None, '_y'))\n",
    "df_merged = df_merged.drop(columns=['title_y', 'link_y', 'score_y']) # drop duplicate columns that were added by the merge\n",
    "\n",
    "print(f\"Full anime data (df1) has size of {df1.shape}.\")\n",
    "print(f\"Anime links data (df2) has size of {df2.shape}.\")\n",
    "print(f\"Merged table (df_merged) has a size of {df_merged.shape}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`keep=False` allows to see all instances of duplication for better analysis. \n",
    "Apparently during the scraping process, this title below was scraped twice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>type</th>\n",
       "      <th>episodes</th>\n",
       "      <th>status</th>\n",
       "      <th>aired</th>\n",
       "      <th>premiered</th>\n",
       "      <th>broadcast</th>\n",
       "      <th>producers</th>\n",
       "      <th>licensors</th>\n",
       "      <th>...</th>\n",
       "      <th>duration</th>\n",
       "      <th>rating</th>\n",
       "      <th>score</th>\n",
       "      <th>ranked</th>\n",
       "      <th>popularity</th>\n",
       "      <th>members</th>\n",
       "      <th>favorites</th>\n",
       "      <th>link</th>\n",
       "      <th>id</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>Zankyou no Terror</td>\n",
       "      <td>Painted in red, the word \"VON\" is all that is ...</td>\n",
       "      <td>TV</td>\n",
       "      <td>\\n  11\\n</td>\n",
       "      <td>\\n  Finished Airing\\n</td>\n",
       "      <td>\\n  Jul 11, 2014 to Sep 26, 2014\\n</td>\n",
       "      <td>Summer 2014</td>\n",
       "      <td>[\\n    Fridays at 00:50 (JST)\\n      ]</td>\n",
       "      <td>[Aniplex, Dentsu, Fuji TV, Tohokushinsha Film ...</td>\n",
       "      <td>[Funimation]</td>\n",
       "      <td>...</td>\n",
       "      <td>\\n  22 min. per ep.\\n</td>\n",
       "      <td>\\n  R - 17+ (violence &amp; profanity)\\n</td>\n",
       "      <td>8.08</td>\n",
       "      <td>\\n  #551</td>\n",
       "      <td>\\n  #122\\n</td>\n",
       "      <td>\\n    1,220,926\\n</td>\n",
       "      <td>\\n  22,796\\n</td>\n",
       "      <td>https://myanimelist.net/anime/23283/Zankyou_no...</td>\n",
       "      <td>23283</td>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>Zankyou no Terror</td>\n",
       "      <td>Painted in red, the word \"VON\" is all that is ...</td>\n",
       "      <td>TV</td>\n",
       "      <td>\\n  11\\n</td>\n",
       "      <td>\\n  Finished Airing\\n</td>\n",
       "      <td>\\n  Jul 11, 2014 to Sep 26, 2014\\n</td>\n",
       "      <td>Summer 2014</td>\n",
       "      <td>[\\n    Fridays at 00:50 (JST)\\n      ]</td>\n",
       "      <td>[Aniplex, Dentsu, Fuji TV, Tohokushinsha Film ...</td>\n",
       "      <td>[Funimation]</td>\n",
       "      <td>...</td>\n",
       "      <td>\\n  22 min. per ep.\\n</td>\n",
       "      <td>\\n  R - 17+ (violence &amp; profanity)\\n</td>\n",
       "      <td>8.08</td>\n",
       "      <td>\\n  #551</td>\n",
       "      <td>\\n  #122\\n</td>\n",
       "      <td>\\n    1,220,926\\n</td>\n",
       "      <td>\\n  22,796\\n</td>\n",
       "      <td>https://myanimelist.net/anime/23283/Zankyou_no...</td>\n",
       "      <td>23283</td>\n",
       "      <td>551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 title                                           synopsis  \\\n",
       "549  Zankyou no Terror  Painted in red, the word \"VON\" is all that is ...   \n",
       "550  Zankyou no Terror  Painted in red, the word \"VON\" is all that is ...   \n",
       "\n",
       "    type    episodes                   status  \\\n",
       "549   TV  \\n  11\\n    \\n  Finished Airing\\n     \n",
       "550   TV  \\n  11\\n    \\n  Finished Airing\\n     \n",
       "\n",
       "                                    aired    premiered  \\\n",
       "549  \\n  Jul 11, 2014 to Sep 26, 2014\\n    Summer 2014   \n",
       "550  \\n  Jul 11, 2014 to Sep 26, 2014\\n    Summer 2014   \n",
       "\n",
       "                                  broadcast  \\\n",
       "549  [\\n    Fridays at 00:50 (JST)\\n      ]   \n",
       "550  [\\n    Fridays at 00:50 (JST)\\n      ]   \n",
       "\n",
       "                                             producers     licensors  ...  \\\n",
       "549  [Aniplex, Dentsu, Fuji TV, Tohokushinsha Film ...  [Funimation]  ...   \n",
       "550  [Aniplex, Dentsu, Fuji TV, Tohokushinsha Film ...  [Funimation]  ...   \n",
       "\n",
       "                    duration                                  rating score  \\\n",
       "549  \\n  22 min. per ep.\\n    \\n  R - 17+ (violence & profanity)\\n    8.08   \n",
       "550  \\n  22 min. per ep.\\n    \\n  R - 17+ (violence & profanity)\\n    8.08   \n",
       "\n",
       "       ranked  popularity            members     favorites  \\\n",
       "549  \\n  #551  \\n  #122\\n  \\n    1,220,926\\n  \\n  22,796\\n   \n",
       "550  \\n  #551  \\n  #122\\n  \\n    1,220,926\\n  \\n  22,796\\n   \n",
       "\n",
       "                                                  link     id rank  \n",
       "549  https://myanimelist.net/anime/23283/Zankyou_no...  23283  550  \n",
       "550  https://myanimelist.net/anime/23283/Zankyou_no...  23283  551  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[df_merged['link'].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's observe the `df_merged` again, but with dropped duplicates this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full anime data (df1) has size of (28209, 24).\n",
      "Anime links data (df2) has size of (28210, 5).\n",
      "Merged table (df_merged) has a size of (28210, 25).\n",
      "Merged table (df_merged) after dropping duplicates has a size of (28209, 25).\n"
     ]
    }
   ],
   "source": [
    "print(f\"Full anime data (df1) has size of {df1.shape}.\")\n",
    "print(f\"Anime links data (df2) has size of {df2.shape}.\")\n",
    "print(f\"Merged table (df_merged) has a size of {df_merged.shape}.\")\n",
    "\n",
    "df_merged = df_merged.drop_duplicates(subset=['id'])\n",
    "\n",
    "print(f\"Merged table (df_merged) after dropping duplicates has a size of {df_merged.shape}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see here, duplication was removed, which makes `df_merged` more consistent with anime links data `df2`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the very first title to scale cleaning technique to entire dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>type</th>\n",
       "      <th>episodes</th>\n",
       "      <th>status</th>\n",
       "      <th>aired</th>\n",
       "      <th>premiered</th>\n",
       "      <th>broadcast</th>\n",
       "      <th>producers</th>\n",
       "      <th>licensors</th>\n",
       "      <th>...</th>\n",
       "      <th>duration</th>\n",
       "      <th>rating</th>\n",
       "      <th>score</th>\n",
       "      <th>ranked</th>\n",
       "      <th>popularity</th>\n",
       "      <th>members</th>\n",
       "      <th>favorites</th>\n",
       "      <th>link</th>\n",
       "      <th>id</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sousou no Frieren</td>\n",
       "      <td>During their decade-long quest to defeat the D...</td>\n",
       "      <td>TV</td>\n",
       "      <td>\\n  28\\n</td>\n",
       "      <td>\\n  Finished Airing\\n</td>\n",
       "      <td>\\n  Sep 29, 2023 to Mar 22, 2024\\n</td>\n",
       "      <td>Fall 2023</td>\n",
       "      <td>[\\n    Fridays at 23:00 (JST)\\n      ]</td>\n",
       "      <td>[Aniplex, Dentsu, Shogakukan-Shueisha Producti...</td>\n",
       "      <td>[Crunchyroll]</td>\n",
       "      <td>...</td>\n",
       "      <td>\\n  24 min. per ep.\\n</td>\n",
       "      <td>\\n  PG-13 - Teens 13 or older\\n</td>\n",
       "      <td>9.31</td>\n",
       "      <td>\\n  #1</td>\n",
       "      <td>\\n  #157\\n</td>\n",
       "      <td>\\n    1,060,746\\n</td>\n",
       "      <td>\\n  65,118\\n</td>\n",
       "      <td>https://myanimelist.net/anime/52991/Sousou_no_...</td>\n",
       "      <td>52991</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               title                                           synopsis type  \\\n",
       "0  Sousou no Frieren  During their decade-long quest to defeat the D...   TV   \n",
       "\n",
       "     episodes                   status                                 aired  \\\n",
       "0  \\n  28\\n    \\n  Finished Airing\\n    \\n  Sep 29, 2023 to Mar 22, 2024\\n     \n",
       "\n",
       "   premiered                               broadcast  \\\n",
       "0  Fall 2023  [\\n    Fridays at 23:00 (JST)\\n      ]   \n",
       "\n",
       "                                           producers      licensors  ...  \\\n",
       "0  [Aniplex, Dentsu, Shogakukan-Shueisha Producti...  [Crunchyroll]  ...   \n",
       "\n",
       "                  duration                             rating score  ranked  \\\n",
       "0  \\n  24 min. per ep.\\n    \\n  PG-13 - Teens 13 or older\\n    9.31  \\n  #1   \n",
       "\n",
       "   popularity            members     favorites  \\\n",
       "0  \\n  #157\\n  \\n    1,060,746\\n  \\n  65,118\\n   \n",
       "\n",
       "                                                link     id rank  \n",
       "0  https://myanimelist.net/anime/52991/Sousou_no_...  52991    1  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>Sousou no Frieren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>synopsis</th>\n",
       "      <td>During their decade-long quest to defeat the D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <td>TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>episodes</th>\n",
       "      <td>\\n  28\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>status</th>\n",
       "      <td>\\n  Finished Airing\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aired</th>\n",
       "      <td>\\n  Sep 29, 2023 to Mar 22, 2024\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>premiered</th>\n",
       "      <td>Fall 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>broadcast</th>\n",
       "      <td>[\\n    Fridays at 23:00 (JST)\\n      ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>producers</th>\n",
       "      <td>[Aniplex, Dentsu, Shogakukan-Shueisha Producti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>licensors</th>\n",
       "      <td>[Crunchyroll]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>studios</th>\n",
       "      <td>[Madhouse]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <td>\\n      Manga\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genres</th>\n",
       "      <td>[Adventure, Drama, Fantasy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demographic</th>\n",
       "      <td>[Shounen]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>themes</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>\\n  24 min. per ep.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <td>\\n  PG-13 - Teens 13 or older\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>9.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ranked</th>\n",
       "      <td>\\n  #1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>popularity</th>\n",
       "      <td>\\n  #157\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>members</th>\n",
       "      <td>\\n    1,060,746\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>favorites</th>\n",
       "      <td>\\n  65,118\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>link</th>\n",
       "      <td>https://myanimelist.net/anime/52991/Sousou_no_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>52991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             0\n",
       "title                                        Sousou no Frieren\n",
       "synopsis     During their decade-long quest to defeat the D...\n",
       "type                                                        TV\n",
       "episodes                                            \\n  28\\n  \n",
       "status                                 \\n  Finished Airing\\n  \n",
       "aired                     \\n  Sep 29, 2023 to Mar 22, 2024\\n  \n",
       "premiered                                            Fall 2023\n",
       "broadcast               [\\n    Fridays at 23:00 (JST)\\n      ]\n",
       "producers    [Aniplex, Dentsu, Shogakukan-Shueisha Producti...\n",
       "licensors                                        [Crunchyroll]\n",
       "studios                                             [Madhouse]\n",
       "source                                     \\n      Manga\\n    \n",
       "genres                             [Adventure, Drama, Fantasy]\n",
       "demographic                                          [Shounen]\n",
       "themes                                                      []\n",
       "duration                               \\n  24 min. per ep.\\n  \n",
       "rating                       \\n  PG-13 - Teens 13 or older\\n  \n",
       "score                                                     9.31\n",
       "ranked                                                  \\n  #1\n",
       "popularity                                          \\n  #157\\n\n",
       "members                                      \\n    1,060,746\\n\n",
       "favorites                                         \\n  65,118\\n\n",
       "link         https://myanimelist.net/anime/52991/Sousou_no_...\n",
       "id                                                       52991\n",
       "rank                                                         1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.head(1).T # Transpose for better visibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I can see that `broadcast` column was scraped as list. This tells me that the original scraper logic had `.getall()` method. Replaced with `.get()` for the next time.\n",
    "\n",
    "- I can see a lot of `\\n`s. Let's use `.apply` method to replace those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the `broadcast` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['broadcast'] = df_merged['broadcast'].explode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the `\\n`s from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>type</th>\n",
       "      <th>episodes</th>\n",
       "      <th>status</th>\n",
       "      <th>aired</th>\n",
       "      <th>premiered</th>\n",
       "      <th>broadcast</th>\n",
       "      <th>producers</th>\n",
       "      <th>licensors</th>\n",
       "      <th>...</th>\n",
       "      <th>duration</th>\n",
       "      <th>rating</th>\n",
       "      <th>score</th>\n",
       "      <th>ranked</th>\n",
       "      <th>popularity</th>\n",
       "      <th>members</th>\n",
       "      <th>favorites</th>\n",
       "      <th>link</th>\n",
       "      <th>id</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sousou no Frieren</td>\n",
       "      <td>During their decade-long quest to defeat the D...</td>\n",
       "      <td>TV</td>\n",
       "      <td>28</td>\n",
       "      <td>Finished Airing</td>\n",
       "      <td>Sep 29, 2023 to Mar 22, 2024</td>\n",
       "      <td>Fall 2023</td>\n",
       "      <td>Fridays at 23:00 (JST)</td>\n",
       "      <td>[Aniplex, Dentsu, Shogakukan-Shueisha Producti...</td>\n",
       "      <td>[Crunchyroll]</td>\n",
       "      <td>...</td>\n",
       "      <td>24 min. per ep.</td>\n",
       "      <td>PG-13 - Teens 13 or older</td>\n",
       "      <td>9.31</td>\n",
       "      <td>#1</td>\n",
       "      <td>#157</td>\n",
       "      <td>1,060,746</td>\n",
       "      <td>65,118</td>\n",
       "      <td>https://myanimelist.net/anime/52991/Sousou_no_...</td>\n",
       "      <td>52991</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>After a horrific alchemy experiment goes wrong...</td>\n",
       "      <td>TV</td>\n",
       "      <td>64</td>\n",
       "      <td>Finished Airing</td>\n",
       "      <td>Apr 5, 2009 to Jul 4, 2010</td>\n",
       "      <td>Spring 2009</td>\n",
       "      <td>Sundays at 17:00 (JST)</td>\n",
       "      <td>[Aniplex, Square Enix, Mainichi Broadcasting S...</td>\n",
       "      <td>[Funimation, Aniplex of America]</td>\n",
       "      <td>...</td>\n",
       "      <td>24 min. per ep.</td>\n",
       "      <td>R - 17+ (violence &amp; profanity)</td>\n",
       "      <td>9.10</td>\n",
       "      <td>#2</td>\n",
       "      <td>#3</td>\n",
       "      <td>3,494,512</td>\n",
       "      <td>232,541</td>\n",
       "      <td>https://myanimelist.net/anime/5114/Fullmetal_A...</td>\n",
       "      <td>5114</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Steins;Gate</td>\n",
       "      <td>Eccentric scientist Rintarou Okabe has a never...</td>\n",
       "      <td>TV</td>\n",
       "      <td>24</td>\n",
       "      <td>Finished Airing</td>\n",
       "      <td>Apr 6, 2011 to Sep 14, 2011</td>\n",
       "      <td>Spring 2011</td>\n",
       "      <td>Wednesdays at 02:05 (JST)</td>\n",
       "      <td>[Frontier Works, Media Factory, Kadokawa Shote...</td>\n",
       "      <td>[Funimation]</td>\n",
       "      <td>...</td>\n",
       "      <td>24 min. per ep.</td>\n",
       "      <td>PG-13 - Teens 13 or older</td>\n",
       "      <td>9.07</td>\n",
       "      <td>#3</td>\n",
       "      <td>#14</td>\n",
       "      <td>2,676,611</td>\n",
       "      <td>195,034</td>\n",
       "      <td>https://myanimelist.net/anime/9253/Steins_Gate</td>\n",
       "      <td>9253</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shingeki no Kyojin Season 3 Part 2</td>\n",
       "      <td>Seeking to restore humanity's diminishing hope...</td>\n",
       "      <td>TV</td>\n",
       "      <td>10</td>\n",
       "      <td>Finished Airing</td>\n",
       "      <td>Apr 29, 2019 to Jul 1, 2019</td>\n",
       "      <td>Spring 2019</td>\n",
       "      <td>Mondays at 00:10 (JST)</td>\n",
       "      <td>[Production I.G, Dentsu, Mainichi Broadcasting...</td>\n",
       "      <td>[Funimation]</td>\n",
       "      <td>...</td>\n",
       "      <td>23 min. per ep.</td>\n",
       "      <td>R - 17+ (violence &amp; profanity)</td>\n",
       "      <td>9.05</td>\n",
       "      <td>#4</td>\n",
       "      <td>#21</td>\n",
       "      <td>2,418,640</td>\n",
       "      <td>60,654</td>\n",
       "      <td>https://myanimelist.net/anime/38524/Shingeki_n...</td>\n",
       "      <td>38524</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>One Piece Fan Letter</td>\n",
       "      <td>Although the golden age of piracy is about to ...</td>\n",
       "      <td>TV Special</td>\n",
       "      <td>1</td>\n",
       "      <td>Finished Airing</td>\n",
       "      <td>Oct 20, 2024</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[add some]</td>\n",
       "      <td>[add some]</td>\n",
       "      <td>...</td>\n",
       "      <td>24 min.</td>\n",
       "      <td>PG-13 - Teens 13 or older</td>\n",
       "      <td>9.05</td>\n",
       "      <td>#5</td>\n",
       "      <td>#2281</td>\n",
       "      <td>96,765</td>\n",
       "      <td>2,034</td>\n",
       "      <td>https://myanimelist.net/anime/60022/One_Piece_...</td>\n",
       "      <td>60022</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title  \\\n",
       "0                   Sousou no Frieren   \n",
       "1    Fullmetal Alchemist: Brotherhood   \n",
       "2                         Steins;Gate   \n",
       "3  Shingeki no Kyojin Season 3 Part 2   \n",
       "4                One Piece Fan Letter   \n",
       "\n",
       "                                            synopsis        type episodes  \\\n",
       "0  During their decade-long quest to defeat the D...          TV     28     \n",
       "1  After a horrific alchemy experiment goes wrong...          TV     64     \n",
       "2  Eccentric scientist Rintarou Okabe has a never...          TV     24     \n",
       "3  Seeking to restore humanity's diminishing hope...          TV     10     \n",
       "4  Although the golden age of piracy is about to ...  TV Special      1     \n",
       "\n",
       "                status                             aired    premiered  \\\n",
       "0    Finished Airing      Sep 29, 2023 to Mar 22, 2024      Fall 2023   \n",
       "1    Finished Airing        Apr 5, 2009 to Jul 4, 2010    Spring 2009   \n",
       "2    Finished Airing       Apr 6, 2011 to Sep 14, 2011    Spring 2011   \n",
       "3    Finished Airing       Apr 29, 2019 to Jul 1, 2019    Spring 2019   \n",
       "4    Finished Airing                      Oct 20, 2024           None   \n",
       "\n",
       "                             broadcast  \\\n",
       "0         Fridays at 23:00 (JST)         \n",
       "1         Sundays at 17:00 (JST)         \n",
       "2      Wednesdays at 02:05 (JST)         \n",
       "3         Mondays at 00:10 (JST)         \n",
       "4                                  NaN   \n",
       "\n",
       "                                           producers  \\\n",
       "0  [Aniplex, Dentsu, Shogakukan-Shueisha Producti...   \n",
       "1  [Aniplex, Square Enix, Mainichi Broadcasting S...   \n",
       "2  [Frontier Works, Media Factory, Kadokawa Shote...   \n",
       "3  [Production I.G, Dentsu, Mainichi Broadcasting...   \n",
       "4                                         [add some]   \n",
       "\n",
       "                          licensors  ...             duration  \\\n",
       "0                     [Crunchyroll]  ...    24 min. per ep.     \n",
       "1  [Funimation, Aniplex of America]  ...    24 min. per ep.     \n",
       "2                      [Funimation]  ...    24 min. per ep.     \n",
       "3                      [Funimation]  ...    23 min. per ep.     \n",
       "4                        [add some]  ...            24 min.     \n",
       "\n",
       "                               rating score ranked popularity        members  \\\n",
       "0         PG-13 - Teens 13 or older    9.31     #1       #157      1,060,746   \n",
       "1    R - 17+ (violence & profanity)    9.10     #2         #3      3,494,512   \n",
       "2         PG-13 - Teens 13 or older    9.07     #3        #14      2,676,611   \n",
       "3    R - 17+ (violence & profanity)    9.05     #4        #21      2,418,640   \n",
       "4         PG-13 - Teens 13 or older    9.05     #5      #2281         96,765   \n",
       "\n",
       "   favorites                                               link     id rank  \n",
       "0     65,118  https://myanimelist.net/anime/52991/Sousou_no_...  52991    1  \n",
       "1    232,541  https://myanimelist.net/anime/5114/Fullmetal_A...   5114    2  \n",
       "2    195,034     https://myanimelist.net/anime/9253/Steins_Gate   9253    3  \n",
       "3     60,654  https://myanimelist.net/anime/38524/Shingeki_n...  38524    4  \n",
       "4      2,034  https://myanimelist.net/anime/60022/One_Piece_...  60022    5  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in df_merged.columns:\n",
    "    df_merged[i] = df_merged[i].apply(lambda x: x.replace(\"\\n\", \"\") if isinstance(x, str) else x)\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title           object\n",
       "synopsis        object\n",
       "type            object\n",
       "episodes        object\n",
       "status          object\n",
       "aired           object\n",
       "premiered       object\n",
       "broadcast       object\n",
       "producers       object\n",
       "licensors       object\n",
       "studios         object\n",
       "source          object\n",
       "genres          object\n",
       "demographic     object\n",
       "themes          object\n",
       "duration        object\n",
       "rating          object\n",
       "score          float64\n",
       "ranked          object\n",
       "popularity      object\n",
       "members         object\n",
       "favorites       object\n",
       "link            object\n",
       "id              object\n",
       "rank            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how I want it to look:\n",
    "\n",
    "- title           object \n",
    "- synopsis        object \n",
    "- type            object \n",
    "- `episodes        int64` \n",
    "- status          object \n",
    "- aired           object \n",
    "- premiered       object \n",
    "- broadcast       object \n",
    "- producers       object \n",
    "- licensors       object \n",
    "- studios         object \n",
    "- source          object \n",
    "- genres          object\n",
    "- demographic     object\n",
    "- themes          object\n",
    "- duration        object\n",
    "- rating          object\n",
    "- score          float64\n",
    "- `ranked          int64 `\n",
    "- `popularity      int64`\n",
    "- `members         int64`\n",
    "- `favorites       int64`\n",
    "- link            object\n",
    "- `id              int64`\n",
    "- `rank            int64`\n",
    "\n",
    "Let's see those columns first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episodes</th>\n",
       "      <th>ranked</th>\n",
       "      <th>popularity</th>\n",
       "      <th>members</th>\n",
       "      <th>favorites</th>\n",
       "      <th>id</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>#1</td>\n",
       "      <td>#157</td>\n",
       "      <td>1,060,746</td>\n",
       "      <td>65,118</td>\n",
       "      <td>52991</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>#2</td>\n",
       "      <td>#3</td>\n",
       "      <td>3,494,512</td>\n",
       "      <td>232,541</td>\n",
       "      <td>5114</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>#3</td>\n",
       "      <td>#14</td>\n",
       "      <td>2,676,611</td>\n",
       "      <td>195,034</td>\n",
       "      <td>9253</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>#4</td>\n",
       "      <td>#21</td>\n",
       "      <td>2,418,640</td>\n",
       "      <td>60,654</td>\n",
       "      <td>38524</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>#5</td>\n",
       "      <td>#2281</td>\n",
       "      <td>96,765</td>\n",
       "      <td>2,034</td>\n",
       "      <td>60022</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28205</th>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>#23413</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>58863</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28206</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>N/A</td>\n",
       "      <td>#18983</td>\n",
       "      <td>353</td>\n",
       "      <td>0</td>\n",
       "      <td>60857</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28207</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>N/A</td>\n",
       "      <td>#11255</td>\n",
       "      <td>2,467</td>\n",
       "      <td>10</td>\n",
       "      <td>57969</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28208</th>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>#18697</td>\n",
       "      <td>375</td>\n",
       "      <td>2</td>\n",
       "      <td>53688</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28209</th>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>#6772</td>\n",
       "      <td>10,078</td>\n",
       "      <td>29</td>\n",
       "      <td>41289</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28209 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          episodes ranked popularity        members  favorites     id rank\n",
       "0             28       #1       #157      1,060,746     65,118  52991    1\n",
       "1             64       #2         #3      3,494,512    232,541   5114    2\n",
       "2             24       #3        #14      2,676,611    195,034   9253    3\n",
       "3             10       #4        #21      2,418,640     60,654  38524    4\n",
       "4              1       #5      #2281         96,765      2,034  60022    5\n",
       "...            ...    ...        ...            ...        ...    ...  ...\n",
       "28205          1      N/A     #23413            129          0  58863    -\n",
       "28206    Unknown      N/A     #18983            353          0  60857    -\n",
       "28207    Unknown      N/A     #11255          2,467         10  57969    -\n",
       "28208          1      N/A     #18697            375          2  53688    -\n",
       "28209          1      N/A      #6772         10,078         29  41289    -\n",
       "\n",
       "[28209 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change_types = ['episodes', 'ranked', 'popularity', 'members', 'favorites', 'id', 'rank']\n",
    "df_merged[change_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episodes</th>\n",
       "      <th>ranked</th>\n",
       "      <th>popularity</th>\n",
       "      <th>members</th>\n",
       "      <th>favorites</th>\n",
       "      <th>id</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>157</td>\n",
       "      <td>1060746</td>\n",
       "      <td>65118</td>\n",
       "      <td>52991</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3494512</td>\n",
       "      <td>232541</td>\n",
       "      <td>5114</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14</td>\n",
       "      <td>2676611</td>\n",
       "      <td>195034</td>\n",
       "      <td>9253</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21</td>\n",
       "      <td>2418640</td>\n",
       "      <td>60654</td>\n",
       "      <td>38524</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2281</td>\n",
       "      <td>96765</td>\n",
       "      <td>2034</td>\n",
       "      <td>60022</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28205</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23413</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>58863</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28206</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18983</td>\n",
       "      <td>353</td>\n",
       "      <td>0</td>\n",
       "      <td>60857</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28207</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11255</td>\n",
       "      <td>2467</td>\n",
       "      <td>10</td>\n",
       "      <td>57969</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28208</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18697</td>\n",
       "      <td>375</td>\n",
       "      <td>2</td>\n",
       "      <td>53688</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28209</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6772</td>\n",
       "      <td>10078</td>\n",
       "      <td>29</td>\n",
       "      <td>41289</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28209 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       episodes  ranked  popularity  members  favorites     id  rank\n",
       "0          28.0     1.0         157  1060746      65118  52991   1.0\n",
       "1          64.0     2.0           3  3494512     232541   5114   2.0\n",
       "2          24.0     3.0          14  2676611     195034   9253   3.0\n",
       "3          10.0     4.0          21  2418640      60654  38524   4.0\n",
       "4           1.0     5.0        2281    96765       2034  60022   5.0\n",
       "...         ...     ...         ...      ...        ...    ...   ...\n",
       "28205       1.0     NaN       23413      129          0  58863   NaN\n",
       "28206       NaN     NaN       18983      353          0  60857   NaN\n",
       "28207       NaN     NaN       11255     2467         10  57969   NaN\n",
       "28208       1.0     NaN       18697      375          2  53688   NaN\n",
       "28209       1.0     NaN        6772    10078         29  41289   NaN\n",
       "\n",
       "[28209 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in change_types:\n",
    "    df_merged[i] = df_merged[i].str.replace(\"#\", \"\").str.replace(\",\", \"\")\n",
    "    df_merged[i] = pd.to_numeric(df_merged[i], errors=\"coerce\")\n",
    "\n",
    "df_merged[change_types]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision: Replace all non-number values with `NaN`s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks clean. Now we can proceed with further analysis of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title              0\n",
       "synopsis           0\n",
       "type            4563\n",
       "episodes         676\n",
       "status             0\n",
       "aired              0\n",
       "premiered      22101\n",
       "broadcast      19971\n",
       "producers          0\n",
       "licensors          0\n",
       "studios            0\n",
       "source         20711\n",
       "genres             0\n",
       "demographic        0\n",
       "themes             0\n",
       "duration           0\n",
       "rating             0\n",
       "score           9971\n",
       "ranked          6661\n",
       "popularity         0\n",
       "members            0\n",
       "favorites          0\n",
       "link               0\n",
       "id                 0\n",
       "rank            6663\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns containing lists: ['producers', 'licensors', 'studios', 'genres', 'demographic', 'themes']\n"
     ]
    }
   ],
   "source": [
    "list_columns = [col for col in df_merged.columns if df_merged[col].apply(lambda x: isinstance(x, list)).any()]\n",
    "print(\"Columns containing lists:\", list_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column names listed abouve will be used to create separate table for SQLite Database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['producers', 'licensors', 'studios', 'genres', 'demographic', 'themes']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_list_like_columns(df: pd.DataFrame) -> list:\n",
    "    list_like_columns = []\n",
    "    for col in df.columns:\n",
    "        if df[col].apply(lambda x: isinstance(x, list)).any():\n",
    "            list_like_columns.append(col)\n",
    "    return list_like_columns\n",
    "fetch_list_like_columns(df_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things start to get complicated from here so I will describe steps that I went through here:\n",
    "- TODO:\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's open the `MAL_data.csv` to check how clean our data is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'MAL_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m final_df=\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mMAL_data.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m.head(\u001b[32m1\u001b[39m).T\n\u001b[32m      2\u001b[39m \u001b[38;5;28mtype\u001b[39m(final_df.loc[\u001b[33m'\u001b[39m\u001b[33mgenres\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m0\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/pythonProjects/MALScraper/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/pythonProjects/MALScraper/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/pythonProjects/MALScraper/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/pythonProjects/MALScraper/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/pythonProjects/MALScraper/.venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'MAL_data.csv'"
     ]
    }
   ],
   "source": [
    "final_df=pd.read_csv('MAL_data.csv').head(1).T\n",
    "type(final_df.loc['genres'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
